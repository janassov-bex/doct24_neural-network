{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f86ba541",
   "metadata": {},
   "source": [
    "# Подготовка данных пациентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a0a42e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sbs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from tqdm import notebook\n",
    "sbs.set_style(\"darkgrid\")\n",
    "\n",
    "# text processing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "# preprocessing/processing\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# model selection\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, cross_validate,  StratifiedKFold\n",
    "import imblearn\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, make_scorer\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score, roc_auc_score\n",
    "\n",
    "# base models\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# model building\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a7f922",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bcf3dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'chd_addmit_300.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "308ce412",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bed50988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admittion</th>\n",
       "      <th>discharge</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BSA</th>\n",
       "      <th>birth</th>\n",
       "      <th>Операции (все в ИБ)</th>\n",
       "      <th>Перенесенные опер. (из Анамн.)</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "      <th>Unnamed: 33</th>\n",
       "      <th>Unnamed: 34</th>\n",
       "      <th>Unnamed: 35</th>\n",
       "      <th>Unnamed: 36</th>\n",
       "      <th>Unnamed: 37</th>\n",
       "      <th>Unnamed: 38</th>\n",
       "      <th>Unnamed: 39</th>\n",
       "      <th>Unnamed: 40</th>\n",
       "      <th>Unnamed: 41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-12-12</td>\n",
       "      <td>2017-01-10</td>\n",
       "      <td>m</td>\n",
       "      <td>76</td>\n",
       "      <td>9.70</td>\n",
       "      <td>111.27</td>\n",
       "      <td>0.46</td>\n",
       "      <td>02.01.2016</td>\n",
       "      <td>12.12.2016: (Откр./ИК) Перевязка ранее наложен...</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-13</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>f</td>\n",
       "      <td>67</td>\n",
       "      <td>7.34</td>\n",
       "      <td>89.67</td>\n",
       "      <td>0.37</td>\n",
       "      <td>02.02.2016</td>\n",
       "      <td>18.01.2017: (Откр./ИК) Радикальная коррекция д...</td>\n",
       "      <td>15.08.2016г.: Транслюминальная балонная вальву...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-17</td>\n",
       "      <td>2017-02-09</td>\n",
       "      <td>m</td>\n",
       "      <td>74</td>\n",
       "      <td>8.90</td>\n",
       "      <td>103.46</td>\n",
       "      <td>0.43</td>\n",
       "      <td>21.02.2016</td>\n",
       "      <td>19.01.2017: (Откр./ИК) Перевязка ранее наложен...</td>\n",
       "      <td>29.02.2016 - подключично-легочный анастомоз сп...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-20</td>\n",
       "      <td>2017-02-21</td>\n",
       "      <td>f</td>\n",
       "      <td>67</td>\n",
       "      <td>6.97</td>\n",
       "      <td>85.15</td>\n",
       "      <td>0.36</td>\n",
       "      <td>02.03.2016</td>\n",
       "      <td>23.01.2017: (Откр./ИК) Наложение двустороннего...</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-02-13</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>m</td>\n",
       "      <td>82</td>\n",
       "      <td>9.29</td>\n",
       "      <td>102.59</td>\n",
       "      <td>0.46</td>\n",
       "      <td>08.03.2016</td>\n",
       "      <td>15.02.2017: (Откр./ИК) Реконструкция путей отт...</td>\n",
       "      <td>13.04.2016. НАЗВАНИЕ ОПЕРАЦИИ: Транслюминальна...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   admittion  discharge sex  height  weight     BMI   BSA       birth  \\\n",
       "0 2016-12-12 2017-01-10   m      76    9.70  111.27  0.46  02.01.2016   \n",
       "1 2017-01-13 2017-02-01   f      67    7.34   89.67  0.37  02.02.2016   \n",
       "2 2017-01-17 2017-02-09   m      74    8.90  103.46  0.43  21.02.2016   \n",
       "3 2017-01-20 2017-02-21   f      67    6.97   85.15  0.36  02.03.2016   \n",
       "4 2017-02-13 2017-03-01   m      82    9.29  102.59  0.46  08.03.2016   \n",
       "\n",
       "                                 Операции (все в ИБ)  \\\n",
       "0  12.12.2016: (Откр./ИК) Перевязка ранее наложен...   \n",
       "1  18.01.2017: (Откр./ИК) Радикальная коррекция д...   \n",
       "2  19.01.2017: (Откр./ИК) Перевязка ранее наложен...   \n",
       "3  23.01.2017: (Откр./ИК) Наложение двустороннего...   \n",
       "4  15.02.2017: (Откр./ИК) Реконструкция путей отт...   \n",
       "\n",
       "                      Перенесенные опер. (из Анамн.)  ... Unnamed: 32  \\\n",
       "0                                                     ...         NaN   \n",
       "1  15.08.2016г.: Транслюминальная балонная вальву...  ...         NaN   \n",
       "2  29.02.2016 - подключично-легочный анастомоз сп...  ...         NaN   \n",
       "3                                                     ...         NaN   \n",
       "4  13.04.2016. НАЗВАНИЕ ОПЕРАЦИИ: Транслюминальна...  ...         NaN   \n",
       "\n",
       "  Unnamed: 33 Unnamed: 34 Unnamed: 35 Unnamed: 36 Unnamed: 37 Unnamed: 38  \\\n",
       "0         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "3         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "4         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "  Unnamed: 39 Unnamed: 40 Unnamed: 41  \n",
       "0         NaN         NaN         NaN  \n",
       "1         NaN         NaN         NaN  \n",
       "2         NaN         NaN         NaN  \n",
       "3         NaN         NaN         NaN  \n",
       "4         NaN         NaN         NaN  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2370e16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 42 columns):\n",
      " #   Column                                           Non-Null Count  Dtype         \n",
      "---  ------                                           --------------  -----         \n",
      " 0   admittion                                        300 non-null    datetime64[ns]\n",
      " 1   discharge                                        300 non-null    datetime64[ns]\n",
      " 2   sex                                              300 non-null    object        \n",
      " 3   height                                           300 non-null    int64         \n",
      " 4   weight                                           300 non-null    float64       \n",
      " 5   BMI                                              298 non-null    float64       \n",
      " 6   BSA                                              298 non-null    float64       \n",
      " 7   birth                                            300 non-null    object        \n",
      " 8   Операции (все в ИБ)                              300 non-null    object        \n",
      " 9   Перенесенные опер. (из Анамн.)                   300 non-null    object        \n",
      " 10  Диагноз                                          300 non-null    object        \n",
      " 11  МКБ                                              300 non-null    object        \n",
      " 12  Соп. забол. (из Анамн.)                          300 non-null    object        \n",
      " 13  Медикам. леч. по поводу осн. забол. (из Анамн.)  253 non-null    object        \n",
      " 14  Принимаемые препараты (из Анамн.)                180 non-null    object        \n",
      " 15  ЭхоКГ (Из Эпикр. до опер.)                       293 non-null    object        \n",
      " 16  ЭКГ (Из Эпикр. до опер.)                         280 non-null    object        \n",
      " 17  АКГ (Из Эпикр. до опер.)                         91 non-null     object        \n",
      " 18  КТ (Из Эпикр. до опер.)                          38 non-null     object        \n",
      " 19  Операция (основная / первая в ИБ)                300 non-null    object        \n",
      " 20  Дата опер.                                       300 non-null    object        \n",
      " 21  target                                           300 non-null    int64         \n",
      " 22  Unnamed: 22                                      0 non-null      float64       \n",
      " 23  Unnamed: 23                                      0 non-null      float64       \n",
      " 24  Unnamed: 24                                      0 non-null      float64       \n",
      " 25  Unnamed: 25                                      0 non-null      float64       \n",
      " 26  Unnamed: 26                                      0 non-null      float64       \n",
      " 27  Unnamed: 27                                      0 non-null      float64       \n",
      " 28  Unnamed: 28                                      0 non-null      float64       \n",
      " 29  Unnamed: 29                                      0 non-null      float64       \n",
      " 30  Unnamed: 30                                      0 non-null      float64       \n",
      " 31  Unnamed: 31                                      0 non-null      float64       \n",
      " 32  Unnamed: 32                                      0 non-null      float64       \n",
      " 33  Unnamed: 33                                      0 non-null      float64       \n",
      " 34  Unnamed: 34                                      0 non-null      float64       \n",
      " 35  Unnamed: 35                                      0 non-null      float64       \n",
      " 36  Unnamed: 36                                      0 non-null      float64       \n",
      " 37  Unnamed: 37                                      0 non-null      float64       \n",
      " 38  Unnamed: 38                                      0 non-null      float64       \n",
      " 39  Unnamed: 39                                      0 non-null      float64       \n",
      " 40  Unnamed: 40                                      0 non-null      float64       \n",
      " 41  Unnamed: 41                                      0 non-null      float64       \n",
      "dtypes: datetime64[ns](2), float64(23), int64(2), object(15)\n",
      "memory usage: 98.6+ KB\n"
     ]
    }
   ],
   "source": [
    "patient_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8715db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BSA</th>\n",
       "      <th>target</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "      <th>Unnamed: 24</th>\n",
       "      <th>Unnamed: 25</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "      <th>Unnamed: 33</th>\n",
       "      <th>Unnamed: 34</th>\n",
       "      <th>Unnamed: 35</th>\n",
       "      <th>Unnamed: 36</th>\n",
       "      <th>Unnamed: 37</th>\n",
       "      <th>Unnamed: 38</th>\n",
       "      <th>Unnamed: 39</th>\n",
       "      <th>Unnamed: 40</th>\n",
       "      <th>Unnamed: 41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>298.000000</td>\n",
       "      <td>298.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>64.890000</td>\n",
       "      <td>6.293560</td>\n",
       "      <td>76.834430</td>\n",
       "      <td>0.336477</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.076012</td>\n",
       "      <td>1.951695</td>\n",
       "      <td>20.640196</td>\n",
       "      <td>0.073846</td>\n",
       "      <td>0.211276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>20.340000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>4.868500</td>\n",
       "      <td>62.007500</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>65.500000</td>\n",
       "      <td>6.442500</td>\n",
       "      <td>78.430000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>71.000000</td>\n",
       "      <td>7.651250</td>\n",
       "      <td>91.797500</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>85.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>137.650000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           height      weight         BMI         BSA      target  \\\n",
       "count  300.000000  300.000000  298.000000  298.000000  300.000000   \n",
       "mean    64.890000    6.293560   76.834430    0.336477    0.046667   \n",
       "std      8.076012    1.951695   20.640196    0.073846    0.211276   \n",
       "min     39.000000    1.270000   20.340000    0.120000    0.000000   \n",
       "25%     60.000000    4.868500   62.007500    0.280000    0.000000   \n",
       "50%     65.500000    6.442500   78.430000    0.350000    0.000000   \n",
       "75%     71.000000    7.651250   91.797500    0.390000    0.000000   \n",
       "max     85.000000   12.000000  137.650000    0.520000    1.000000   \n",
       "\n",
       "       Unnamed: 22  Unnamed: 23  Unnamed: 24  Unnamed: 25  Unnamed: 26  ...  \\\n",
       "count          0.0          0.0          0.0          0.0          0.0  ...   \n",
       "mean           NaN          NaN          NaN          NaN          NaN  ...   \n",
       "std            NaN          NaN          NaN          NaN          NaN  ...   \n",
       "min            NaN          NaN          NaN          NaN          NaN  ...   \n",
       "25%            NaN          NaN          NaN          NaN          NaN  ...   \n",
       "50%            NaN          NaN          NaN          NaN          NaN  ...   \n",
       "75%            NaN          NaN          NaN          NaN          NaN  ...   \n",
       "max            NaN          NaN          NaN          NaN          NaN  ...   \n",
       "\n",
       "       Unnamed: 32  Unnamed: 33  Unnamed: 34  Unnamed: 35  Unnamed: 36  \\\n",
       "count          0.0          0.0          0.0          0.0          0.0   \n",
       "mean           NaN          NaN          NaN          NaN          NaN   \n",
       "std            NaN          NaN          NaN          NaN          NaN   \n",
       "min            NaN          NaN          NaN          NaN          NaN   \n",
       "25%            NaN          NaN          NaN          NaN          NaN   \n",
       "50%            NaN          NaN          NaN          NaN          NaN   \n",
       "75%            NaN          NaN          NaN          NaN          NaN   \n",
       "max            NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "       Unnamed: 37  Unnamed: 38  Unnamed: 39  Unnamed: 40  Unnamed: 41  \n",
       "count          0.0          0.0          0.0          0.0          0.0  \n",
       "mean           NaN          NaN          NaN          NaN          NaN  \n",
       "std            NaN          NaN          NaN          NaN          NaN  \n",
       "min            NaN          NaN          NaN          NaN          NaN  \n",
       "25%            NaN          NaN          NaN          NaN          NaN  \n",
       "50%            NaN          NaN          NaN          NaN          NaN  \n",
       "75%            NaN          NaN          NaN          NaN          NaN  \n",
       "max            NaN          NaN          NaN          NaN          NaN  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a65610c",
   "metadata": {},
   "source": [
    "Успешно создан датасет. Необходимо изменить тип данных некоторых признаков, убрать пропуски."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f505295",
   "metadata": {},
   "source": [
    "## Предобработка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497f91fe",
   "metadata": {},
   "source": [
    "### Main dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df16e587",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dataset = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cae6b821",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dataset[['sex',\n",
    "              'height',\n",
    "              'weight',\n",
    "              'BMI','BSA',\n",
    "              'operations',\n",
    "              'target']] = patient_data[['sex',\n",
    "                                         'height',\n",
    "                                         'weight',\n",
    "                                         'BMI',\n",
    "                                         'BSA',\n",
    "                                         'Операции (все в ИБ)',\n",
    "                                         'target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095c0eb8",
   "metadata": {},
   "source": [
    "### Уберем пропуски"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cea058e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex           0\n",
       "height        0\n",
       "weight        0\n",
       "BMI           2\n",
       "BSA           2\n",
       "operations    0\n",
       "target        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6945cb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dataset = main_dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41aa7737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex           0\n",
       "height        0\n",
       "weight        0\n",
       "BMI           0\n",
       "BSA           0\n",
       "operations    0\n",
       "target        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a601180",
   "metadata": {},
   "source": [
    "### Обработка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8265253b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mystem()\n",
    "\n",
    "# Леммантизирует текст\n",
    "def lemmatize(text):\n",
    "    return \"\".join(m.lemmatize(text))\n",
    "\n",
    "def clear_text(text):\n",
    "    cleaned = re.sub(r'[^а-яА-Яa-zA-ZёЁ ]', ' ', text)\n",
    "    cleaned = cleaned.split()\n",
    "    return ' '.join(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a75efab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 422 ms\n",
      "Wall time: 4min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "corpus = main_dataset['operations'].apply(lambda x: clear_text(lemmatize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c664a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dataset['operations'] = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f8fe0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BSA</th>\n",
       "      <th>operations</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>m</td>\n",
       "      <td>51</td>\n",
       "      <td>3.100</td>\n",
       "      <td>43.41</td>\n",
       "      <td>0.21</td>\n",
       "      <td>откр ик ушивание аортолевожелудочкого тоннель ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>f</td>\n",
       "      <td>67</td>\n",
       "      <td>6.245</td>\n",
       "      <td>76.29</td>\n",
       "      <td>0.34</td>\n",
       "      <td>откр ик протезирование трикуспидальный клапан ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>f</td>\n",
       "      <td>65</td>\n",
       "      <td>5.500</td>\n",
       "      <td>68.22</td>\n",
       "      <td>0.32</td>\n",
       "      <td>откр ик пластика дефект межжелудочковый перего...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>f</td>\n",
       "      <td>74</td>\n",
       "      <td>8.580</td>\n",
       "      <td>99.74</td>\n",
       "      <td>0.42</td>\n",
       "      <td>откр ик пластика дефект межжелудочковый перего...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>m</td>\n",
       "      <td>70</td>\n",
       "      <td>6.750</td>\n",
       "      <td>80.68</td>\n",
       "      <td>0.37</td>\n",
       "      <td>откр ик перевязка ранее налагать анастомоз по ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sex  height  weight    BMI   BSA  \\\n",
       "251   m      51   3.100  43.41  0.21   \n",
       "15    f      67   6.245  76.29  0.34   \n",
       "64    f      65   5.500  68.22  0.32   \n",
       "181   f      74   8.580  99.74  0.42   \n",
       "38    m      70   6.750  80.68  0.37   \n",
       "\n",
       "                                            operations  target  \n",
       "251  откр ик ушивание аортолевожелудочкого тоннель ...       0  \n",
       "15   откр ик протезирование трикуспидальный клапан ...       0  \n",
       "64   откр ик пластика дефект межжелудочковый перего...       0  \n",
       "181  откр ик пластика дефект межжелудочковый перего...       0  \n",
       "38   откр ик перевязка ранее налагать анастомоз по ...       0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_dataset.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d15819",
   "metadata": {},
   "source": [
    "### Категории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdc50269",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dataset['sex'] = pd.get_dummies(main_dataset['sex'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf31875a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BSA</th>\n",
       "      <th>operations</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>4.374</td>\n",
       "      <td>56.47</td>\n",
       "      <td>0.27</td>\n",
       "      <td>закрывать операция Muller суживание легочный а...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>3.400</td>\n",
       "      <td>47.15</td>\n",
       "      <td>0.22</td>\n",
       "      <td>закрывать резекция коарктация аорта с наложени...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>6.290</td>\n",
       "      <td>78.62</td>\n",
       "      <td>0.34</td>\n",
       "      <td>откр ик радикальный коррекция открытый общий а...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>6.550</td>\n",
       "      <td>86.01</td>\n",
       "      <td>0.33</td>\n",
       "      <td>откр ик устранение перерыв дуга аорта с помощь...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>12.000</td>\n",
       "      <td>137.65</td>\n",
       "      <td>0.51</td>\n",
       "      <td>откр ик пластик дефект межпредсердный перегоро...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sex  height  weight     BMI   BSA  \\\n",
       "182    0      60   4.374   56.47  0.27   \n",
       "206    1      52   3.400   47.15  0.22   \n",
       "115    0      64   6.290   78.62  0.34   \n",
       "172    0      58   6.550   86.01  0.33   \n",
       "244    1      76  12.000  137.65  0.51   \n",
       "\n",
       "                                            operations  target  \n",
       "182  закрывать операция Muller суживание легочный а...       0  \n",
       "206  закрывать резекция коарктация аорта с наложени...       0  \n",
       "115  откр ик радикальный коррекция открытый общий а...       0  \n",
       "172  откр ик устранение перерыв дуга аорта с помощь...       0  \n",
       "244  откр ик пластик дефект межпредсердный перегоро...       0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_dataset.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2cddd1",
   "metadata": {},
   "source": [
    "### Обучение\n",
    "\n",
    "#### Text Features Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47417d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Стивен\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63e6f2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk_stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f969c1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "operations_transformer = TfidfVectorizer(stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8b338502",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['height', 'weight', 'BMI', 'BSA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "60b2b5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_transformer = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d193e45",
   "metadata": {},
   "source": [
    "#### Column Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "14a98a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', operations_transformer, 'operations'),\n",
    "        ('num', num_transformer, num_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e83d9d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(298, 266)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit_transform(main_dataset).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "925934cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = main_dataset.drop('target', axis=1), main_dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c89442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6132ca83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 6)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "54b31a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 6)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0749153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    198\n",
       "1     10\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "720ce3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    86\n",
       "1     4\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b703a54",
   "metadata": {},
   "source": [
    "### Выбор модели\n",
    "\n",
    "Сделаем пайплайн на примере кэтбуст. Проверим на кросс валидации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5a69e6",
   "metadata": {},
   "source": [
    "### Pipeline + RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2793a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(clf):\n",
    "    pipeline = imbpipeline(\n",
    "        steps=[\n",
    "            ('preprocess', preprocessor),\n",
    "            ('undersampler', RandomUnderSampler(sampling_strategy=0.1)),\n",
    "            ('smote', SMOTE()),\n",
    "            ('clf', clf)\n",
    "        ]\n",
    "    )\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cad0893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search(clf, params, n_iter=10):\n",
    "    clf = create_pipeline(clf)\n",
    "    return RandomizedSearchCV(clf,\n",
    "                              params,\n",
    "                              scoring='neg_log_loss',\n",
    "                              n_jobs=-1,\n",
    "                              n_iter=n_iter,\n",
    "                              cv=StratifiedKFold(n_splits=3, shuffle=True),\n",
    "                              verbose=5\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0df2340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_labels(pos_probs, threshold):\n",
    "    return (pos_probs >= threshold).astype('int')\n",
    "\n",
    "def thresholds_argmax(model, x, y):\n",
    "    thresholds = np.arange(0, 0.9, 0.001)\n",
    "    probs = model.predict_proba(x)[:, 1]\n",
    "    scores = [roc_auc_score(y, to_labels(probs, t)) for t in thresholds]\n",
    "    ix = np.argmax(scores)\n",
    "    threshold = thresholds[ix]\n",
    "    return (threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "a84ec174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_data(model, show_feature_importance=False):\n",
    "    clf_name = model.estimator['clf'].__class__.__name__\n",
    "    print(f'Classifier name: {clf_name}')\n",
    "    \n",
    "    model = model.fit(X_train, y_train)\n",
    "    print(f'Training finished!', '-'*100, sep='\\n')\n",
    "    print(f'Best score: = {model.best_score_}')\n",
    "    print(f'Best parameters {model.best_params_}')\n",
    "    \n",
    "    if show_feature_importance:   \n",
    "        try:\n",
    "            if clf_name == 'CatBoostClassifier':\n",
    "                feature_importance = model.best_estimator_['clf'].get_feature_importance()\n",
    "            elif clf_name == 'XGBClassifier':\n",
    "                feature_importance = model.best_estimator_['clf'].feature_importances_\n",
    "            else:\n",
    "                feature_importance = feature_importance = model.best_estimator_['clf'].feature_importance_\n",
    "            main_features = pd.DataFrame(data = feature_importance[-5:], index=X.columns[:5]).sort_values(by=0)\n",
    "            \n",
    "            plt.figure(figsize=(10, 7))\n",
    "            main_features.plot(kind='barh', ax=plt.gca())\n",
    "            plt.title('Feature Importance without operations')\n",
    "            plt.xlabel('Importance, %')\n",
    "            plt.show()\n",
    "        except:\n",
    "            print('no feature importance')\n",
    "    \n",
    "    best_model = model.best_estimator_.fit(X_train, y_train)\n",
    "    th = thresholds_argmax(best_model, X_test, y_test)\n",
    "    print(f'Threshold: {th}')\n",
    "    predictions = best_model.predict_proba(X_test)[:,1] > th\n",
    "    print(f'Confusion Matrix:\\n {confusion_matrix(y_test, predictions)}')\n",
    "    print(classification_report(y_test, predictions))\n",
    "    f1 = f1_score(y_test, predictions, labels=[1])\n",
    "    \n",
    "    return best_model, th, abs(model.best_score_), f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce0919f",
   "metadata": {},
   "source": [
    "### Перебор моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "0cb6f371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def look_through_models(models):\n",
    "    names = []\n",
    "    nest_models = []\n",
    "    data_list = []\n",
    "    for model in notebook.tqdm(models):\n",
    "        data = fit_data(model)\n",
    "        names.append(data[0]['clf'].__class__.__name__)\n",
    "        nest_models.append(data[0])\n",
    "        data_list.append(data[1:])\n",
    "        print('_'*100)\n",
    "    \n",
    "    data_df = pd.DataFrame(data=data_list, index=names)\n",
    "    display(data_df)\n",
    "    data_df[0].sort_values(0).plot(kind='barh', ax=plt.gca())\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.show()\n",
    "    data_df[1].sort_values(0, ascending=False).plot(kind='barh', ax=plt.gca())\n",
    "    plt.xlabel('Log loss score')\n",
    "    plt.show()\n",
    "    data_df[2].sort_values(0).plot(kind='barh', ax=plt.gca())\n",
    "    plt.xlabel('f1 score')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "7e3dff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "fa2e9c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tree\n",
    "parameters = {\n",
    "    'clf__max_depth': range(3, 10),\n",
    "    'preprocess__text__ngram_range': ((1, 1), (1, 2), (1, 3)),\n",
    "    'smote__sampling_strategy': np.arange(0.2, 0.8, 0.1)\n",
    "}\n",
    "\n",
    "svc = random_search(DecisionTreeClassifier(),\n",
    "                          parameters,\n",
    "                          3)\n",
    "models.append(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "3780d6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SGD\n",
    "parameters = {\n",
    "    'preprocess__text__ngram_range': ((1, 1), (1, 2), (1, 3)),\n",
    "    'smote__sampling_strategy': np.arange(0.2, 0.8, 0.1)\n",
    "}\n",
    "\n",
    "svc = random_search(SGDClassifier(loss='log_loss'),\n",
    "                          parameters,\n",
    "                          3)\n",
    "models.append(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "1085d4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "parameters = {\n",
    "    'clf__n_neighbors': range(3, 10),\n",
    "    'preprocess__text__ngram_range': ((1, 1), (1, 2), (1, 3)),\n",
    "    'smote__sampling_strategy': np.arange(0.2, 0.8, 0.1)\n",
    "}\n",
    "\n",
    "svc = random_search(KNeighborsClassifier(),\n",
    "                          parameters,\n",
    "                          3)\n",
    "models.append(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "57d3f14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forest\n",
    "parameters = {\n",
    "    'clf__max_depth': range(3, 10),\n",
    "    'clf__n_estimators': range(100, 1000, 100),\n",
    "    'preprocess__text__ngram_range': ((1, 1), (1, 2), (1, 3)),\n",
    "    'smote__sampling_strategy': np.arange(0.2, 0.8, 0.1)\n",
    "}\n",
    "\n",
    "svc = random_search(RandomForestClassifier(),\n",
    "                          parameters,\n",
    "                          3)\n",
    "models.append(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "439a9c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic\n",
    "parameters = {\n",
    "    'clf__C': [1, 4, 6],\n",
    "    'preprocess__text__ngram_range': ((1, 1), (1, 2), (1, 3)),\n",
    "    'smote__sampling_strategy': np.arange(0.2, 0.8, 0.1)\n",
    "}\n",
    "\n",
    "svc = random_search(LogisticRegression(),\n",
    "                          parameters,\n",
    "                          3)\n",
    "models.append(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "ffd3b83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC\n",
    "parameters = {\n",
    "    'clf__gamma': [.1,.5,1,2,5,10],\n",
    "    'clf__C': [.1, 1, 10, 100, 1000],\n",
    "    'preprocess__text__ngram_range': ((1, 1), (1, 2), (1, 3)),\n",
    "    'smote__sampling_strategy': np.arange(0.2, 0.8, 0.1)\n",
    "}\n",
    "\n",
    "svc = random_search(SVC(probability=True, kernel='rbf'),\n",
    "                          parameters,\n",
    "                          3)\n",
    "models.append(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "6001a420",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#CatBoost\n",
    "parameters = {\n",
    "    'preprocess__text__ngram_range': ((1, 1), (1, 2), (1, 3)),\n",
    "    'smote__sampling_strategy': np.arange(0.2, 0.8, 0.1),\n",
    "    'clf__depth': range(2, 11),\n",
    "}\n",
    "\n",
    "catboost_search = random_search(CatBoostClassifier(silent=True, iterations=750),\n",
    "                                       parameters,\n",
    "                                       3\n",
    "                                       )\n",
    "models.append(catboost_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "6d8bf32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGB\n",
    "parameters = {\n",
    "    'preprocess__text__ngram_range': ((1, 1), (1, 2), (1, 3)),\n",
    "    'smote__sampling_strategy': np.arange(0.2, 0.8, 0.1),\n",
    "    'clf__max_depth': range(2, 11),\n",
    "}\n",
    "\n",
    "xgb_search = random_search(XGBClassifier(),\n",
    "                          parameters,\n",
    "                          3)\n",
    "models.append(xgb_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e15a6ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1b37976a80461ababe3e7524aeab5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier name: DecisionTreeClassifier\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Training finished!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Best score: = -2.4742515775740936\n",
      "Best parameters {'smote__sampling_strategy': 0.2, 'preprocess__text__ngram_range': (1, 3), 'clf__max_depth': 3}\n",
      "Threshold: 0.04\n",
      "Confusion Matrix:\n",
      " [[83  3]\n",
      " [ 3  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        86\n",
      "           1       0.25      0.25      0.25         4\n",
      "\n",
      "    accuracy                           0.93        90\n",
      "   macro avg       0.61      0.61      0.61        90\n",
      "weighted avg       0.93      0.93      0.93        90\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier name: SGDClassifier\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Training finished!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Best score: = -0.5330176603635813\n",
      "Best parameters {'smote__sampling_strategy': 0.8000000000000003, 'preprocess__text__ngram_range': (1, 2)}\n",
      "Threshold: 0.004\n",
      "Confusion Matrix:\n",
      " [[72 14]\n",
      " [ 1  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91        86\n",
      "           1       0.18      0.75      0.29         4\n",
      "\n",
      "    accuracy                           0.83        90\n",
      "   macro avg       0.58      0.79      0.60        90\n",
      "weighted avg       0.95      0.83      0.88        90\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier name: KNeighborsClassifier\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Training finished!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Best score: = -1.6858375917777977\n",
      "Best parameters {'smote__sampling_strategy': 0.8000000000000003, 'preprocess__text__ngram_range': (1, 3), 'clf__n_neighbors': 9}\n",
      "Threshold: 0.112\n",
      "Confusion Matrix:\n",
      " [[33 53]\n",
      " [ 0  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.38      0.55        86\n",
      "           1       0.07      1.00      0.13         4\n",
      "\n",
      "    accuracy                           0.41        90\n",
      "   macro avg       0.54      0.69      0.34        90\n",
      "weighted avg       0.96      0.41      0.54        90\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier name: RandomForestClassifier\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Training finished!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Best score: = -0.15127989450139595\n",
      "Best parameters {'smote__sampling_strategy': 0.30000000000000004, 'preprocess__text__ngram_range': (1, 3), 'clf__n_estimators': 300, 'clf__max_depth': 4}\n",
      "Threshold: 0.145\n",
      "Confusion Matrix:\n",
      " [[82  4]\n",
      " [ 2  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        86\n",
      "           1       0.33      0.50      0.40         4\n",
      "\n",
      "    accuracy                           0.93        90\n",
      "   macro avg       0.65      0.73      0.68        90\n",
      "weighted avg       0.95      0.93      0.94        90\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier name: LogisticRegression\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Training finished!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Best score: = -0.18045967560381637\n",
      "Best parameters {'smote__sampling_strategy': 0.2, 'preprocess__text__ngram_range': (1, 3), 'clf__C': 6}\n",
      "Threshold: 0.106\n",
      "Confusion Matrix:\n",
      " [[78  8]\n",
      " [ 1  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95        86\n",
      "           1       0.27      0.75      0.40         4\n",
      "\n",
      "    accuracy                           0.90        90\n",
      "   macro avg       0.63      0.83      0.67        90\n",
      "weighted avg       0.96      0.90      0.92        90\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier name: SVC\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Training finished!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Best score: = -0.21070094751351873\n",
      "Best parameters {'smote__sampling_strategy': 0.2, 'preprocess__text__ngram_range': (1, 1), 'clf__gamma': 2, 'clf__C': 100}\n",
      "Threshold: 0.08\n",
      "Confusion Matrix:\n",
      " [[54 32]\n",
      " [ 0  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.63      0.77        86\n",
      "           1       0.11      1.00      0.20         4\n",
      "\n",
      "    accuracy                           0.64        90\n",
      "   macro avg       0.56      0.81      0.49        90\n",
      "weighted avg       0.96      0.64      0.75        90\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier name: CatBoostClassifier\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Training finished!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Best score: = -0.19455613647034087\n",
      "Best parameters {'smote__sampling_strategy': 0.5000000000000001, 'preprocess__text__ngram_range': (1, 2), 'clf__depth': 7}\n"
     ]
    }
   ],
   "source": [
    "look_through_models(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf36427e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896e318d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
