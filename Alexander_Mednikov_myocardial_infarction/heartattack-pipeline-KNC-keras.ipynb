{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, f1_score, precision_score, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"evgeni_set.csv\")\n",
    "df['age'] = df['age']/110 #нормализация\n",
    "\n",
    "#Меня не устраивает что  в train_test_split может в тестовую выборку попасть 0 инфарктов или все 100\n",
    "#поэтому разделю вручную и соеденю после деления обратно\n",
    "df_heartattack_x = df[df['minf']==1].iloc[:, 1:]\n",
    "df_heartattack_y = df[df['minf']==1].iloc[:, 0]\n",
    "df_no_heartattack_x = df[df['minf']==0].iloc[:, 1:]\n",
    "df_no_heartattack_y = df[df['minf']==0].iloc[:, 0]\n",
    "\n",
    "df_heartattack_x_train, df_heartattack_x_test, df_heartattack_y_train, df_heartattack_y_test = train_test_split(df_heartattack_x, df_heartattack_y, test_size=0.2)\n",
    "df_no_heartattack_x_train, df_no_heartattack_x_test, df_no_heartattack_y_train, df_no_heartattack_y_test = train_test_split(df_no_heartattack_x, df_no_heartattack_y, test_size=0.2)\n",
    "\n",
    "x_train = pd.concat((df_heartattack_x_train, df_no_heartattack_x_train), axis=0)\n",
    "y_train = pd.concat((df_heartattack_y_train, df_no_heartattack_y_train), axis=0)\n",
    "x_test = pd.concat((df_heartattack_x_test, df_no_heartattack_x_test), axis=0)\n",
    "y_test = pd.concat((df_heartattack_y_test, df_no_heartattack_y_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[759  30]\n",
      " [  0  21]]\n",
      "recall: 1.0\n",
      "precision: 0.4117647058823529\n",
      "accuracy_score: 0.9629629629629629\n",
      "Доля обектов отнесеных к классу 1 от тестовой выборки: 6%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=2, algorithm='ball_tree')\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(matrix)\n",
    "print(\"recall: \"+str(recall_score(y_test, y_pred)))\n",
    "print(\"precision: \"+str(precision_score(y_test, y_pred)))\n",
    "print(\"accuracy_score: \"+str(accuracy_score(y_test, y_pred)))\n",
    "print(\"Доля обектов отнесеных к классу 1 от тестовой выборки: \"+str(round((sum(matrix[:, 1])/x_test.shape[0])*100))+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(x_train)\n",
    "confusion_matrix(y_train, y_train_pred)\n",
    "x_train_for_pipeline = x_train[y_train_pred==1]\n",
    "y_train_for_pipeline = y_train[y_train_pred==1]\n",
    "x_test_for_pipeline = x_test[y_pred==1]\n",
    "y_test_for_pipeline = y_test[y_pred==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#перебровал много вариантов методом тыка, нейросеть предпочитает все относить либо к единице либо к нулю\n",
    "model = Sequential()\n",
    "model.add(Dense(125, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=Adam(0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6093\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6093\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6093\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6093\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6093\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6093\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6093\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6093\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6093\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x261a6f323b0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_for_pipeline, y_train_for_pipeline, batch_size=20, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.28246212],\n",
       "       [0.27215534],\n",
       "       [0.27294832],\n",
       "       [0.2721235 ],\n",
       "       [0.3076946 ],\n",
       "       [0.27215534],\n",
       "       [0.28246212],\n",
       "       [0.28926358],\n",
       "       [0.27294832],\n",
       "       [0.31527993],\n",
       "       [0.26798865],\n",
       "       [0.27215534],\n",
       "       [0.2721235 ],\n",
       "       [0.28246212],\n",
       "       [0.30170575],\n",
       "       [0.2975321 ],\n",
       "       [0.26798865],\n",
       "       [0.3076946 ],\n",
       "       [0.27294832],\n",
       "       [0.30170575],\n",
       "       [0.30796003],\n",
       "       [0.28246212],\n",
       "       [0.31758845],\n",
       "       [0.31758845],\n",
       "       [0.29558176],\n",
       "       [0.31758845],\n",
       "       [0.2980043 ],\n",
       "       [0.27215534],\n",
       "       [0.31758845],\n",
       "       [0.31758845],\n",
       "       [0.2980043 ],\n",
       "       [0.27215534],\n",
       "       [0.2980043 ],\n",
       "       [0.31758845],\n",
       "       [0.2975321 ],\n",
       "       [0.28246212],\n",
       "       [0.27215534],\n",
       "       [0.27215534],\n",
       "       [0.29558176],\n",
       "       [0.28246212],\n",
       "       [0.2980043 ],\n",
       "       [0.2975321 ],\n",
       "       [0.29558176],\n",
       "       [0.31758845],\n",
       "       [0.31758845],\n",
       "       [0.2980043 ],\n",
       "       [0.28246212],\n",
       "       [0.31758845],\n",
       "       [0.28246212],\n",
       "       [0.2975321 ],\n",
       "       [0.29558176]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_from_pipeline = model.predict(x_test_for_pipeline)\n",
    "y_pred_from_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step\n",
      "7/7 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "e:\\Anaconda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "e:\\Anaconda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "e:\\Anaconda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "e:\\Anaconda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "e:\\Anaconda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "e:\\Anaconda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "e:\\Anaconda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "e:\\Anaconda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "e:\\Anaconda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "e:\\Anaconda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "e:\\Anaconda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "e:\\Anaconda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "e:\\Anaconda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "e:\\Anaconda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "e:\\Anaconda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "e:\\Anaconda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "e:\\Anaconda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(x_test_for_pipeline)[:, 0]\n",
    "prediction_train = model.predict(x_train_for_pipeline)[:, 0]\n",
    "results = {'threshold':[], 'test_recall_score':[], 'test_f1_score':[], 'test_precision_score':[]\n",
    "           , 'train_recall_score':[], 'train_f1_score':[], 'train_precision_score':[]}\n",
    "iters = prediction.copy()\n",
    "iters.sort()\n",
    "\n",
    "for i in iters:\n",
    "    predict_mine = []\n",
    "    for i2 in prediction:\n",
    "        if i2>i:\n",
    "            predict_mine.append(1)\n",
    "        else:\n",
    "            predict_mine.append(0)\n",
    "\n",
    "    train_predict_mine = []\n",
    "    for i3 in prediction_train:\n",
    "        if i3>i:\n",
    "            train_predict_mine.append(1)\n",
    "        else:\n",
    "            train_predict_mine.append(0)\n",
    "            \n",
    "    results['threshold'].append(i)\n",
    "    results['test_recall_score'].append(recall_score(y_test_for_pipeline, predict_mine))\n",
    "    results['test_f1_score'].append(f1_score(y_test_for_pipeline, predict_mine))\n",
    "    results['test_precision_score'].append(precision_score(y_test_for_pipeline, predict_mine))\n",
    "    results['train_recall_score'].append(recall_score(y_train_for_pipeline, train_predict_mine))\n",
    "    results['train_f1_score'].append(f1_score(y_train_for_pipeline, train_predict_mine))\n",
    "    results['train_precision_score'].append(precision_score(y_train_for_pipeline, train_predict_mine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>test_recall_score</th>\n",
       "      <th>test_f1_score</th>\n",
       "      <th>test_precision_score</th>\n",
       "      <th>train_recall_score</th>\n",
       "      <th>train_f1_score</th>\n",
       "      <th>train_precision_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.267989</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.940476</td>\n",
       "      <td>0.537415</td>\n",
       "      <td>0.376190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.267989</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.940476</td>\n",
       "      <td>0.537415</td>\n",
       "      <td>0.376190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.272123</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.361702</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.512111</td>\n",
       "      <td>0.360976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.272123</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.361702</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.512111</td>\n",
       "      <td>0.360976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.272155</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.459016</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.496454</td>\n",
       "      <td>0.353535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.272155</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.459016</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.496454</td>\n",
       "      <td>0.353535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.272155</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.459016</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.496454</td>\n",
       "      <td>0.353535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.272155</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.459016</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.496454</td>\n",
       "      <td>0.353535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.272155</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.459016</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.496454</td>\n",
       "      <td>0.353535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.272155</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.459016</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.496454</td>\n",
       "      <td>0.353535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.272155</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.459016</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.496454</td>\n",
       "      <td>0.353535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.272948</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.474820</td>\n",
       "      <td>0.340206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.272948</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.474820</td>\n",
       "      <td>0.340206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.272948</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.474820</td>\n",
       "      <td>0.340206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.282462</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.494024</td>\n",
       "      <td>0.371257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.282462</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.494024</td>\n",
       "      <td>0.371257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.282462</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.494024</td>\n",
       "      <td>0.371257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.282462</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.494024</td>\n",
       "      <td>0.371257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.282462</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.494024</td>\n",
       "      <td>0.371257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.282462</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.494024</td>\n",
       "      <td>0.371257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.282462</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.494024</td>\n",
       "      <td>0.371257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.282462</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.494024</td>\n",
       "      <td>0.371257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.289264</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.347826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.295582</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.473430</td>\n",
       "      <td>0.398374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.295582</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.473430</td>\n",
       "      <td>0.398374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.295582</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.473430</td>\n",
       "      <td>0.398374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.295582</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.473430</td>\n",
       "      <td>0.398374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.297532</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.488636</td>\n",
       "      <td>0.467391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.297532</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.488636</td>\n",
       "      <td>0.467391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.297532</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.488636</td>\n",
       "      <td>0.467391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.297532</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.488636</td>\n",
       "      <td>0.467391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.298004</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.580645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.298004</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.580645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.298004</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.580645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.298004</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.580645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.298004</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.580645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.301706</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.369048</td>\n",
       "      <td>0.439716</td>\n",
       "      <td>0.543860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.301706</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.369048</td>\n",
       "      <td>0.439716</td>\n",
       "      <td>0.543860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.307695</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.226190</td>\n",
       "      <td>0.311475</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.307695</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.226190</td>\n",
       "      <td>0.311475</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.307960</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.154762</td>\n",
       "      <td>0.224138</td>\n",
       "      <td>0.406250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.315280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>0.269231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.317588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.317588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.317588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.317588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.317588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.317588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.317588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.317588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.317588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshold  test_recall_score  test_f1_score  test_precision_score  \\\n",
       "0    0.267989           0.904762       0.542857              0.387755   \n",
       "1    0.267989           0.904762       0.542857              0.387755   \n",
       "2    0.272123           0.809524       0.500000              0.361702   \n",
       "3    0.272123           0.809524       0.500000              0.361702   \n",
       "4    0.272155           0.666667       0.459016              0.350000   \n",
       "5    0.272155           0.666667       0.459016              0.350000   \n",
       "6    0.272155           0.666667       0.459016              0.350000   \n",
       "7    0.272155           0.666667       0.459016              0.350000   \n",
       "8    0.272155           0.666667       0.459016              0.350000   \n",
       "9    0.272155           0.666667       0.459016              0.350000   \n",
       "10   0.272155           0.666667       0.459016              0.350000   \n",
       "11   0.272948           0.523810       0.379310              0.297297   \n",
       "12   0.272948           0.523810       0.379310              0.297297   \n",
       "13   0.272948           0.523810       0.379310              0.297297   \n",
       "14   0.282462           0.380952       0.320000              0.275862   \n",
       "15   0.282462           0.380952       0.320000              0.275862   \n",
       "16   0.282462           0.380952       0.320000              0.275862   \n",
       "17   0.282462           0.380952       0.320000              0.275862   \n",
       "18   0.282462           0.380952       0.320000              0.275862   \n",
       "19   0.282462           0.380952       0.320000              0.275862   \n",
       "20   0.282462           0.380952       0.320000              0.275862   \n",
       "21   0.282462           0.380952       0.320000              0.275862   \n",
       "22   0.289264           0.333333       0.285714              0.250000   \n",
       "23   0.295582           0.333333       0.311111              0.291667   \n",
       "24   0.295582           0.333333       0.311111              0.291667   \n",
       "25   0.295582           0.333333       0.311111              0.291667   \n",
       "26   0.295582           0.333333       0.311111              0.291667   \n",
       "27   0.297532           0.285714       0.292683              0.300000   \n",
       "28   0.297532           0.285714       0.292683              0.300000   \n",
       "29   0.297532           0.285714       0.292683              0.300000   \n",
       "30   0.297532           0.285714       0.292683              0.300000   \n",
       "31   0.298004           0.285714       0.333333              0.400000   \n",
       "32   0.298004           0.285714       0.333333              0.400000   \n",
       "33   0.298004           0.285714       0.333333              0.400000   \n",
       "34   0.298004           0.285714       0.333333              0.400000   \n",
       "35   0.298004           0.285714       0.333333              0.400000   \n",
       "36   0.301706           0.190476       0.235294              0.307692   \n",
       "37   0.301706           0.190476       0.235294              0.307692   \n",
       "38   0.307695           0.095238       0.125000              0.181818   \n",
       "39   0.307695           0.095238       0.125000              0.181818   \n",
       "40   0.307960           0.047619       0.064516              0.100000   \n",
       "41   0.315280           0.000000       0.000000              0.000000   \n",
       "42   0.317588           0.000000       0.000000              0.000000   \n",
       "43   0.317588           0.000000       0.000000              0.000000   \n",
       "44   0.317588           0.000000       0.000000              0.000000   \n",
       "45   0.317588           0.000000       0.000000              0.000000   \n",
       "46   0.317588           0.000000       0.000000              0.000000   \n",
       "47   0.317588           0.000000       0.000000              0.000000   \n",
       "48   0.317588           0.000000       0.000000              0.000000   \n",
       "49   0.317588           0.000000       0.000000              0.000000   \n",
       "50   0.317588           0.000000       0.000000              0.000000   \n",
       "\n",
       "    train_recall_score  train_f1_score  train_precision_score  \n",
       "0             0.940476        0.537415               0.376190  \n",
       "1             0.940476        0.537415               0.376190  \n",
       "2             0.880952        0.512111               0.360976  \n",
       "3             0.880952        0.512111               0.360976  \n",
       "4             0.833333        0.496454               0.353535  \n",
       "5             0.833333        0.496454               0.353535  \n",
       "6             0.833333        0.496454               0.353535  \n",
       "7             0.833333        0.496454               0.353535  \n",
       "8             0.833333        0.496454               0.353535  \n",
       "9             0.833333        0.496454               0.353535  \n",
       "10            0.833333        0.496454               0.353535  \n",
       "11            0.785714        0.474820               0.340206  \n",
       "12            0.785714        0.474820               0.340206  \n",
       "13            0.785714        0.474820               0.340206  \n",
       "14            0.738095        0.494024               0.371257  \n",
       "15            0.738095        0.494024               0.371257  \n",
       "16            0.738095        0.494024               0.371257  \n",
       "17            0.738095        0.494024               0.371257  \n",
       "18            0.738095        0.494024               0.371257  \n",
       "19            0.738095        0.494024               0.371257  \n",
       "20            0.738095        0.494024               0.371257  \n",
       "21            0.738095        0.494024               0.371257  \n",
       "22            0.666667        0.457143               0.347826  \n",
       "23            0.583333        0.473430               0.398374  \n",
       "24            0.583333        0.473430               0.398374  \n",
       "25            0.583333        0.473430               0.398374  \n",
       "26            0.583333        0.473430               0.398374  \n",
       "27            0.511905        0.488636               0.467391  \n",
       "28            0.511905        0.488636               0.467391  \n",
       "29            0.511905        0.488636               0.467391  \n",
       "30            0.511905        0.488636               0.467391  \n",
       "31            0.428571        0.493151               0.580645  \n",
       "32            0.428571        0.493151               0.580645  \n",
       "33            0.428571        0.493151               0.580645  \n",
       "34            0.428571        0.493151               0.580645  \n",
       "35            0.428571        0.493151               0.580645  \n",
       "36            0.369048        0.439716               0.543860  \n",
       "37            0.369048        0.439716               0.543860  \n",
       "38            0.226190        0.311475               0.500000  \n",
       "39            0.226190        0.311475               0.500000  \n",
       "40            0.154762        0.224138               0.406250  \n",
       "41            0.083333        0.127273               0.269231  \n",
       "42            0.000000        0.000000               0.000000  \n",
       "43            0.000000        0.000000               0.000000  \n",
       "44            0.000000        0.000000               0.000000  \n",
       "45            0.000000        0.000000               0.000000  \n",
       "46            0.000000        0.000000               0.000000  \n",
       "47            0.000000        0.000000               0.000000  \n",
       "48            0.000000        0.000000               0.000000  \n",
       "49            0.000000        0.000000               0.000000  \n",
       "50            0.000000        0.000000               0.000000  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_threshold=pd.DataFrame(results)\n",
    "df_threshold"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
